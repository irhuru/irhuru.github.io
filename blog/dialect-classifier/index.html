<!DOCTYPE html>
<html lang="en-us">
    <head>
        
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-173447074-1', 'auto');
	
	ga('send', 'pageview');
}
</script>

        
        <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="chrome=1">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="referrer" content="no-referrer">
<meta name="description" content="Irati Hurtado. Language Analyst | Communications Specialist">
<title>
Using Machine Learning to Build a Dialect Classifier - Irati Hurtado
</title>



        <meta property="og:title" content="Using machine learning to build a dialect classifier - Irati Hurtado" />
<meta property="og:type" content="website" />
<meta property="og:description" content="Python project that analyzes language data from different Spanish countries and determines the dialect or variety it belongs to"/>
<meta property="og:url" content="https://irhuru.github.io/blog/dialect-classifier/"/>
<meta property="og:site_name" content="Irati Hurtado"/>



<meta property="og:image" content="https://irhuru.github.io/blog/dialect-classifier/dialect-classifier.jpg"/>

<meta property="og:image" content="https://irhuru.github.io/blog/dialect-classifier/movies.jpg"/>

<meta property="og:image" content="https://irhuru.github.io/blog/dialect-classifier/sklearn.jpg"/>



        
<link rel="shortcut icon" href="/img/fav.ico">


        





<link rel="stylesheet" href="/css/main.min.daa833377fb1636f8cbfa65c601050bb5475623deb7aa6e6fdde94a064a6185d.css" integrity="sha256-2qgzN3&#43;xY2&#43;Mv6ZcYBBQu1R1Yj3reqbm/d6UoGSmGF0=" crossorigin="anonymous" media="screen">





        
        
        
        
    </head>
    <body>
        <section id="top" class="section">
            
            <div class="container hero  fade-in one ">
                

<h1 class="bold-title is-1">Blog</h1>


            </div>
            
            <div class="section  fade-in two ">
                
<div class="container">
    <hr>
    <nav class="navbar" role="navigation" aria-label="main navigation">
        
        <a role="button" class="navbar-burger" data-target="navMenu" aria-label="menu" aria-expanded="false" >
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
        </a>
        <div class="navbar-menu " id="navMenu">
            
            
            
            
            <a class="navbar-item" href="/">
                
                Home
                
            </a>
            
            
            
            <a class="navbar-item" href="/#about">
                
                About
                
            </a>
            
            
            
            <a class="navbar-item" href="/projects/">
                
                Projects
                
            </a>
            
            
            
            <a class="navbar-item" href="/blog/">
                
                Blog
                
            </a>
            
            
            
            <a class="navbar-item" href="/#contact">
                
                Contact
                
            </a>
            
            
            
        </div>
    </nav>
    <hr>
</div>



                
<div class="container">
    <h2 class="title is-1 top-pad strong-post-title">
        <a href="https://irhuru.github.io/blog/dialect-classifier/">Using machine learning to build a dialect classifier</a>
    </h2>
    <div class="post-data">
        Jan 17, 2021 |
        5 minutes read
    </div>
    
    <div class="blog-share">
        Share this:
        
        <a class="twitter-share-button" href="https://twitter.com/intent/tweet?text=Using%20machine%20learning%20to%20build%20a%20dialect%20classifier%20https%3a%2f%2firhuru.github.io%2fblog%2fdialect-classifier%2f" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
            <i class="fab fa-twitter"></i>
            <span class="hidden">Twitter</span>
        </a>
        
        
        <a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2firhuru.github.io%2fblog%2fdialect-classifier%2f" onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
            <i class="fab fa-facebook-f"></i>
            <span class="hidden">Facebook</span>
        </a>
        
        
        <a class="icon-pinterest" href="http://pinterest.com/pin/create/button/?url=https%3a%2f%2firhuru.github.io%2fblog%2fdialect-classifier%2f&amp;description=Using%20machine%20learning%20to%20build%20a%20dialect%20classifier" onclick="window.open(this.href, 'pinterest-share','width=580,height=296');return false;">
            <i class="fab fa-pinterest-p"></i>
            <span class="hidden">Pinterest</span>
        </a>
        
        
    </div>
    
    
    
    <p>
        Tags:
        
        <a href="/tags/python">Python</a>,
        
        <a href="/tags/machine-learning">Machine learning</a>,
        
        <a href="/tags/data-analysis">Data analysis</a>
        
    </p>
    
</div>

<div class="container markdown top-pad">
    <p><img src="dialect-classifier.jpg" alt="dialect-classifier"></p>
<p>As a linguist, I have always been curious about <strong>how computers can make sense of texts that combine different languages or language varieties</strong>. Therefore, I decided to learn more about this and implemented a dialect classifier. That is, an algorithm that would take some text as input and would determine the language variety (or dialect) it represents. To find out how I did it, read this post or take a look at <a href="https://github.com/irhuru/dialect-classifier/blob/main/DialectClassifier_code.ipynb">this Jupyter notebook</a> with all the code! ü§ì</p>
<h1 id="the-data">The data</h1>
<!-- raw HTML omitted -->
<p>For this project, I used <strong>data in Spanish</strong>. Spanish is an official language in 20 countries, and it varies greatly from one country to another, which could be an advantage when training the model.</p>
<p>I used data from <strong>two different dialects or varieties: Spain üá™üá∏ and Mexico üá≤üáΩ</strong>. The reason for this is that the greatest differences in terms of dialects occur between Spain and Latin American countries. Out of all Spanish-speaking countries in Latin America, I just happened to find more data from Mexico, but any other country would have equally worked. In the future, I expect to expand this project by adding data from other Spanish varieties.</p>
<p>Regarding the specifics of the dataset, it&rsquo;s very simple and it consists of <strong>Spanish movie subtitles</strong> üé•. There are subtitles from 4 movies produced in Spain and 4 movies produced in Mexico. The movies are:</p>
<ul>
<li><em>Dolor y Gloria</em> (2019), Spain</li>
<li><em>Julieta</em> (2016), Spain</li>
<li><em>La Piel que Habito</em> (2011), Spain</li>
<li><em>Los Abrazos Rotos</em> (2009), Spain</li>
<li><em>Cindy la Regia</em> (2020), Mexico</li>
<li><em>Roma</em> (2018), Mexico</li>
<li><em>La Distadura Perfecta</em> (2014), Mexico</li>
<li><em>Frida</em> (2002), Mexico</li>
</ul>
<p><img src="movies.jpg" alt="movies"></p>
<p>You can access the data <a href="https://github.com/irhuru/dialect-classifier/blob/main/spanish_subtitles_corpus.csv">here</a>, which is in .csv format. The <strong>dataset has 4 columns</strong>:</p>
<ul>
<li><strong>Line</strong>: each subtitle line is numbered (this number restarts whenever the movie title changes).</li>
<li><strong>Subtitle</strong>: the actual text from each subtitle line.</li>
<li><strong>Movie</strong>: the title of the movie the subtitle line belongs to.</li>
<li><strong>Country</strong>: country where the movie is from (either Spain or Mexico)</li>
</ul>
<pre><code># First ten rows of the dataset

line,subtitle,movie,country,
1,Me gustar√ça ser un hombre,dolor_y_gloria,spain,
2,para ba√ëarme en el r√ço desnuda.,dolor_y_gloria,spain,
3,¬°Qu√â valor!,dolor_y_gloria,spain,
4,&quot;¬°Qu√â cosas tienes, Rosita!&quot;,dolor_y_gloria,spain,
5,Di que s√ç.,dolor_y_gloria,spain,
6,Y que te d√â bien el agua en todo el pepe.,dolor_y_gloria,spain,
7,&quot;- ¬°Hija m√ça, qu√â gusto!&quot;,dolor_y_gloria,spain,
8,&quot;- Pues s√ç, pues s√ç.&quot;,dolor_y_gloria,spain,
9,&quot;Oye, antes de echarte al agua,&quot;,dolor_y_gloria,spain,
</code></pre><!-- raw HTML omitted -->
<p>I had to do some pre-processing to clean the data (using the <code>pandas</code> library and regex), as there were some issues with the spelling and punctuation of many of the subtitle lines.</p>
<h1 id="the-model">The model</h1>
<p>The goal of this project was to use machine learning to train <strong>a model that could determine whether a given sentence (i.e., subtitle line) represented the Spanish spoken in Spain or the Spanish spoken in Mexico</strong>.</p>
<p>For example, a sentence like <code>est√° bien chiquito</code> (&ldquo;it&rsquo;s very small&rdquo;) is characteristic from Mexico, as speakers from Spain would use <code>es muy peque√±o</code> instead (same meaning but different vocabulary). It is precisely these dialectal differences that I wanted my model to be able to recognize.</p>
<p>Since the data I had was already labeled (&lsquo;country&rsquo; column), I used a classification algorithm. Even though there are several machine learning algorithms for classification, I decided to use a <strong>Naive Bayes classifier</strong>. These are a type of probabilistic model derived from Bayes&rsquo; Theorem. I won&rsquo;t go into the details of the algorithm in this post, but you can find a nice explanation <a href="https://en.wikipedia.org/wiki/Bayes%27_theorem">here</a> or in <a href="https://github.com/irhuru/dialect-classifier/blob/main/DialectClassifier_code.ipynb">the code I used</a>. Basically, this model would calculate the probability of a sentence being from Mexico and the probability of a sentence being from Spain. Then, it would choose the option with the highest probability.</p>
<p>I used the <code>sklearn</code> library from Python to implement the model following the steps below.</p>
<p><img src="sklearn.jpg" alt="sklearn"></p>
<h2 id="steps">Steps</h2>
<ol>
<li>I used <strong>label encoding</strong> for the &lsquo;country&rsquo; column, which is required to later use our machine learning algorithm. Label encoding converts the labels (&lsquo;Spain&rsquo; and &lsquo;Mexico&rsquo;) into numbers (0 and 1), as that is considered machine-readable form. To do this, I used <code>LabelEncoder()</code> from scikit-learn.</li>
</ol>
<pre><code>label_encoder = preprocessing.LabelEncoder()
df['country'] = label_encoder.fit_transform(df['country'])
</code></pre><!-- raw HTML omitted -->
<ol start="2">
<li>The next step was to <strong>split my dataset into training and testing</strong>. I used 70% of the data for training and 30% for testing (this is common practice in the field). After this, I ended up with four datasets: <code>X_train</code>, <code>X_test</code>, <code>y_train</code>, and <code>y_test</code>. The hyperparameter <code>random_state</code> is a random number that I included for replicability purposes.</li>
</ol>
<pre><code>X_train, X_test, y_train, y_test = train_test_split(df['subtitle'], df['country'], test_size=0.3,random_state=142)
</code></pre><!-- raw HTML omitted -->
<ol start="3">
<li>I split the subtitle lines into <strong>individual words</strong> using <code>CountVectorizer()</code>. I did this to work with individual words instead of with full sentences. This is a good strategy, as many sentences (subtitle lines) might be unique in the dataset. The output should be a vocabulary list.</li>
</ol>
<pre><code>vectorizer = CountVectorizer()
training_data = vectorizer.fit_transform(X_train.values)
</code></pre><!-- raw HTML omitted -->
<ol start="4">
<li>I fitted a <strong>Multinomial Naive Bayes model</strong>. Multinomial models are used for discrete data. That is, when we are not only interested in the presence or absence of a feature, but also on how frequent that feature is. Likewise, I also decided to apply <strong>Laplace smoothing</strong> (additive smoothing) to avoid the zero-frequency problem.</li>
</ol>
<pre><code>naive_bayes_classifier = MultinomialNB(alpha=1.0)
naive_bayes_classifier.fit(training_data, y_train)
</code></pre><!-- raw HTML omitted -->
<ol start="5">
<li>After fitting the model, I used it to <strong>predict</strong> the values from the the testing dataset. Of course, I had to transform that dataset into individual words first.</li>
</ol>
<pre><code>testing_data = vectorizer.transform(X_test.values)
y_pred = naive_bayes_classifier.predict(testing_data)
</code></pre><h1 id="model-evaluation">Model evaluation</h1>
<p>Once the model was fitted and the values from the testing set were predicted, I <strong>evaluated how good the model was</strong> ‚úÖ. I did this by creating a confusion matrix and by calculating the accuracy, precision, and recall from the model. You can read more about these metrics <a href="https://sentimllc.com/accuracy-precision-recall.html">here</a>.</p>
<pre><code># Cofusion matrix

def get_cmatrix(test_data, pred_data):
  return metrics.confusion_matrix(test_data, pred_data)

array_cf = get_cmatrix(y_test, y_pred)
print(array_cf)
</code></pre><pre><code># Accuracy, precision, and recall

print(&quot;Accuracy:&quot;,metrics.accuracy_score(y_test, y_pred))
print(&quot;Precision:&quot;, metrics.precision_score(y_test, y_pred, average='binary'))
print(&quot;Recall:&quot;, metrics.recall_score(y_test, y_pred, average='binary'))
</code></pre><h1 id="conclusion">Conclusion</h1>
<p>I implemented a machine learning model to tease apart whether a specific subtitle lines was more characteristic from Spain or from Mexico. Overall, the model was not very good at predicting the values (accuracy: 70%), probably due to the subtitle lines not exhibiting a lot of dialectal variation. In the future, I will add data from other sources and from other countries in an attempt to build a more diverse dataset.</p>

</div>

<div id="disqus_thread"></div>
<script>
(function() {
var d = document, s = d.createElement('script');
s.src = 'https://irhuru.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>



                
                <div class="container">
    <hr>
</div>
<div class="container has-text-centered top-pad">
    <a href="#top">
        <i class="fa fa-arrow-up"></i>
    </a>
</div>

<div class="container">
    <hr>
</div>

                <div class="section" id="footer">
    <div class="container has-text-centered">
    
        <span class="footer-text">
            <a href="https://github.com/victoriadrake/hugo-theme-introduction/"><strong>Introduction</strong></a> theme for <a href="http://gohugo.io/">Hugo</a>. Made with <a href="https://victoria.dev"><!-- raw HTML omitted --><!-- raw HTML omitted --> and <!-- raw HTML omitted --><!-- raw HTML omitted --></a> by open source contributors.
        </span>
    
    </div>
</div>

                
            </div>
        </section>
        
        


<script src="https://irhuru.github.io/js/bundle.e6934e69d06bb8a213134f4c1468f9478bb7755e786dfb60e3c5a917c5335805.js" integrity="sha256-5pNOadBruKITE09MFGj5R4u3dV54bftg48WpF8UzWAU="></script>


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-173447074-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


        
        
        
        
    </body>
</html>
